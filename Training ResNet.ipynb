{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f19dc0",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37774f",
   "metadata": {},
   "source": [
    "# Set up directories\n",
    "* This code was used to train a ResNet model on Video Plankton Recorder derived images, called Regions of Interest (ROI). \n",
    "* To use this code, all you need to do is to have a training and validation dataset split beforehand. \n",
    "#### Please input your base directory where you \"Train\" and \"Validation\" folders are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base directory (modify this path to your local dataset location)\n",
    "base_dir = r\"./data/Combined_dataset\"\n",
    "\n",
    "train_folder = os.path.join(base_dir, \"Train\")\n",
    "validation_folder = os.path.join(base_dir, \"Validation\")\n",
    "\n",
    "# Check if directories exist\n",
    "for folder, name in zip([train_folder, validation_folder], [\"Training\", \"Validation\"]):\n",
    "    if not os.path.exists(folder):\n",
    "        raise FileNotFoundError(f\"{name} folder '{folder}' not found. Please check your dataset path.\")\n",
    "\n",
    "def count_tif_images(folder):\n",
    "    count = 0\n",
    "    for _, _, files in os.walk(folder):\n",
    "        count += sum(1 for f in files if f.lower().endswith('.tif'))\n",
    "    return count\n",
    "\n",
    "print(f\"Training images: {count_tif_images(train_folder)}\")\n",
    "print(f\"Validation images: {count_tif_images(validation_folder)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a612b77",
   "metadata": {},
   "source": [
    "# Calculate normalization values\n",
    "* Based on the training dataset\n",
    "* This may take some minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee65f7-c37b-436e-bbb9-0de1f0dc8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "image_size = (224, 224) # Input size necessary for ResNet images. \n",
    "\n",
    "# Define a transformation without normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = datasets.ImageFolder(root=train_folder, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, num_workers=4)\n",
    "\n",
    "# Function to calculate mean and std\n",
    "def calculate_mean_std(loader, device):\n",
    "    mean = torch.zeros(3, device=device)  \n",
    "    std = torch.zeros(3, device=device)  \n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            batch_samples = images.size(0)\n",
    "            images = images.view(batch_samples, 3, -1)\n",
    "            mean += images.mean(dim=[0, 2]) * batch_samples\n",
    "            std += images.std(dim=[0, 2]) * batch_samples\n",
    "            total_samples += batch_samples\n",
    "\n",
    "    mean /= total_samples\n",
    "    std /= total_samples\n",
    "    return mean.cpu(), std.cpu()\n",
    "\n",
    "# Calculate and display mean/std\n",
    "mean, std = calculate_mean_std(train_loader, device)\n",
    "calculated_mean = mean.tolist()\n",
    "calculated_std = std.tolist()\n",
    "print(f\"Calculated Mean: {calculated_mean}\")\n",
    "print(f\"Calculated Std: {calculated_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4629c44",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "* Includes random horizontal+vertical flips to the training data, to improve generalization of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for training data\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((image_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=calculated_mean, \n",
    "                         std=calculated_std)    \n",
    "])\n",
    "\n",
    "# Define data transformations for validation data\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=calculated_mean, \n",
    "                         std=calculated_std)    \n",
    "])\n",
    "\n",
    "# Load train and validation datasets with transformations\n",
    "train_dataset = datasets.ImageFolder(root=train_folder, transform=transform_train)\n",
    "validation_dataset = datasets.ImageFolder(root=validation_folder, transform=transform_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb7067a",
   "metadata": {},
   "source": [
    "# Set model and hyperparameters\n",
    "* Also prints a table of all hyperparameters used.\n",
    "* Inputs: ResNet model (number of layers) and hyperparameters\n",
    "* Batch size, learning rate, epochs, weighted loss, and LRScheduler\n",
    "* Current parameters are what was used for a 3-class model classifying VPR images of Marine snow, Fecal pellets, and Others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose ResNet model\n",
    "resnet_model = resnet34 # resnetXX, where XX is number of layers desired. \n",
    "# Initiate model with no weights, training from scratch\n",
    "model = resnet_model(weights=None, num_classes=len(train_dataset.classes)).to(device)\n",
    "\n",
    "#### Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001 # initial learning rate\n",
    "num_epochs = 30 # number of epochs\n",
    "loss = \"weighted\" # change this  if not using weighted loss\n",
    "LRScheduler = \"ROP\" # reduce on plateau | = \"ROP\" if using. Change if not using.  \n",
    "\n",
    "#### LOSS FUNCTION \n",
    "## Implement weighted loss function, assigning higher penalties to underrepresented classes\n",
    "## Define min and max weight thresholds\n",
    "if loss == \"weighted\":\n",
    "    max_weight_threshold = 5.0  # Prevent extreme rare class weighting\n",
    "    min_weight_threshold = 0.5  # Ensure majority classes are not ignored\n",
    "    ## Get class distribution from dataset\n",
    "    class_counts = np.bincount(train_dataset.targets)  # Count samples per class\n",
    "    num_classes = len(class_counts)\n",
    "    ## Compute weights: inverse of class frequency\n",
    "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.arange(num_classes), y=train_dataset.targets)\n",
    "    class_weights = np.clip(class_weights, min_weight_threshold, max_weight_threshold) # cap the weights\n",
    "    ## Convert to PyTorch tensor and send to device\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss() # replace with above if using weight loss function. \n",
    "\n",
    "# Optimizer uses calculated loss to adjust the weights, reducing loss.\n",
    "# Adam optimizer automatically adjusts learning rate for each parameter\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create a learning rate scheduler, either StepLR or ReduceLROnPlateau\n",
    "if LRScheduler == \"ROP\": \n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=4, verbose=True) #remember to alter the factor\n",
    "else:\n",
    "    LRScheduler = \"StepLR\"\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Create a pandas DataFrame for a proper table\n",
    "hyperparams = pd.DataFrame([\n",
    "    [\"Model\", str(resnet_model)],\n",
    "    [\"Batch Size\", batch_size],\n",
    "    [\"Learning Rate\", learning_rate],\n",
    "    [\"Epochs\", num_epochs],\n",
    "    [\"Loss Function\", loss],\n",
    "    [\"Optimizer\", str(optimizer)],\n",
    "    [\"Scheduler\", LRScheduler]\n",
    "], columns=[\"Parameter\", \"Value\"])\n",
    "\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b484fb70",
   "metadata": {},
   "source": [
    "# Load data loaders with transformations\n",
    "* Num_workers controls parallel loading of data. Higher values lead to faster data fetching, but requires a more powerful CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "\n",
    "# DataLoader for train & validation datasets\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, \n",
    "    num_workers=num_workers, pin_memory=True, persistent_workers=True,\n",
    ")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, persistent_workers=True,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dac108",
   "metadata": {},
   "source": [
    "# Lists to store metrics\n",
    "* Remember to reset these lists between each training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store true labels and predicted labels\n",
    "true_labels_list = []\n",
    "predicted_labels_list = []\n",
    "\n",
    "# Lists to store loss and accuracies\n",
    "train_losses = []\n",
    "train_accuracies = [] \n",
    "validation_losses = []\n",
    "validation_accuracies = []\n",
    "\n",
    "# Lists for classwise precision and recall + F1\n",
    "classwise_precision = []\n",
    "classwise_recall = []\n",
    "classwise_f1 = []\n",
    "\n",
    "\n",
    "#Store all metrics for each class across each epoch\n",
    "class_metrics = {class_name: {\"train\": [], \"val\": [], \"precision\": [], \"recall\": [], \"f1\": []} for class_name in train_dataset.classes}\n",
    "# Initialize dictionaries to store FP FN TP and TN for each class and epoch. This will containt accumualted metrics over all epochs. \n",
    "class_metrics2 = {class_name: {\"FP\": [], \"FN\": [], \"TP\": [], \"TN\": []} for class_name in train_dataset.classes}\n",
    "\n",
    "# Initialize counters for each class\n",
    "num_classes = len(train_dataset.classes)\n",
    "class_correct = [0] * num_classes\n",
    "class_total = [0] * num_classes\n",
    "class_train_correct = [0] * num_classes\n",
    "class_train_total = [0] * num_classes\n",
    "class_val_correct = [0] * num_classes\n",
    "class_val_total = [0] * num_classes\n",
    "\n",
    "# Lists to store F1 scores\n",
    "macro_f1_scores = []\n",
    "weighted_f1_scores = []\n",
    "epochs_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e71574d-fabd-426b-8d34-364f51da7d04",
   "metadata": {},
   "source": [
    "# Train and validate the model\n",
    "* This code block will begin training the model, and performance data.\n",
    "* This code also saves the best weights (determined by highest F1 score).\n",
    "* Inputs: Patience (stops training if no improvements in X epochs.\n",
    "* After each epoch, the code will report time taken for training and validation. Then, it will report F1 scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress all UndefinedMetricWarning warnings where precision and recall = 0. \n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "# Best F1 score and model weights initialization\n",
    "best_weighted_f1 = 0.0  # Stores the best weighted F1-score\n",
    "best_macro_f1 = 0.0 # Stores best macro F1 score\n",
    "best_model_wts = None  # Stores the best model weights in memory\n",
    "\n",
    "# Early stopping parameters\n",
    "epochs_without_improvement = 0\n",
    "patience = 8  # Stop if no improvement in x epochs\n",
    "\n",
    "#################### Training loop ####################################################################\n",
    "print(\"Initiating training\")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    start_time = time.time()  # Start the timer\n",
    "\n",
    "    # Reset class_train_correct and class_train_total for each epoch\n",
    "    class_train_correct = [0] * num_classes\n",
    "    class_train_total = [0] * num_classes\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    true_labels_train = []\n",
    "    predicted_labels_train = []\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        true_labels_train.extend(labels.cpu().numpy())\n",
    "        predicted_labels_train.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Update class-wise counts and training metrics\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i].item()\n",
    "            class_correct[label] += (predicted[i] == label)\n",
    "            class_total[label] += 1\n",
    "            class_train_correct[label] += (predicted[i] == label)\n",
    "            class_train_total[label] += 1\n",
    "    \n",
    "    # End the timer and calculate elapsed time\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f\"Time taken for training epoch {epoch}: {epoch_time:.0f} seconds\")\n",
    "        \n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(100 * correct_train / total_train)  # Store total training accuracy\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score for training\n",
    "    train_precision = precision_score(true_labels_train, predicted_labels_train, average='weighted')\n",
    "    train_recall = recall_score(true_labels_train, predicted_labels_train, average='weighted')\n",
    "    train_f1 = f1_score(true_labels_train, predicted_labels_train, average='weighted')    \n",
    "\n",
    "########################### Validation loop #######################################################################\n",
    "    model.eval()\n",
    "    start_time = time.time()  # Start the timer\n",
    "    validation_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    true_labels_val = []\n",
    "    predicted_labels_val = []\n",
    "\n",
    "    # Reset class_val_correct and class_val_total for each epoch\n",
    "    class_val_correct = [0] * num_classes\n",
    "    class_val_total = [0] * num_classes   \n",
    "    \n",
    "    # For each epoch, reset class_metrics3. \n",
    "    class_metrics3 = {class_name: {\"FP\": [], \"FN\": [], \"TP\": [], \"TN\": []} for class_name in train_dataset.classes}  # Create a new dictionary for each epoch\n",
    "\n",
    "    for images, labels in validation_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        validation_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_val += labels.size(0)\n",
    "\n",
    "        \n",
    "        # Calculate TP, FP, TN, FN for each class\n",
    "        for class_name in train_dataset.classes:\n",
    "            class_index = train_dataset.class_to_idx[class_name]\n",
    "            true_positive = ((predicted == class_index) & (labels == class_index)).sum().item()\n",
    "            false_positive = ((predicted == class_index) & (labels != class_index)).sum().item()\n",
    "            true_negative = ((predicted != class_index) & (labels != class_index)).sum().item()\n",
    "            false_negative = ((predicted != class_index) & (labels == class_index)).sum().item()\n",
    "\n",
    "            # Append these metrics to the class_metrics2 dictionary, for accumulated values.\n",
    "            class_metrics2[class_name][\"TP\"].append(true_positive)\n",
    "            class_metrics2[class_name][\"FP\"].append(false_positive)\n",
    "            class_metrics2[class_name][\"TN\"].append(true_negative)\n",
    "            class_metrics2[class_name][\"FN\"].append(false_negative)\n",
    "\n",
    "            # Append these metrics to the class_metrics2 dictionary, for individual epoch values.\n",
    "            #These dictionaries are exactly the same, but class_metrics3 is reset after every epoch, thus empty at this point.\n",
    "            class_metrics3[class_name][\"TP\"].append(true_positive)\n",
    "            class_metrics3[class_name][\"FP\"].append(false_positive)\n",
    "            class_metrics3[class_name][\"TN\"].append(true_negative)\n",
    "            class_metrics3[class_name][\"FN\"].append(false_negative)\n",
    "            # and at this point it has filled in the NEWEST values of TP FP TN and FN. \n",
    "        \n",
    "        correct_val += (predicted == labels).sum().item()\n",
    "        true_labels_val.extend(labels.cpu().numpy())\n",
    "        predicted_labels_val.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Update class-wise counts for validation\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i].item()\n",
    "            class_val_correct[label] += (predicted[i] == label)\n",
    "            class_val_total[label] += 1\n",
    "       \n",
    "    # Append validation accuracy and loss\n",
    "    validation_losses.append(validation_loss / len(validation_loader))\n",
    "    validation_accuracies.append(100 * correct_val / total_val)\n",
    "\n",
    "    # Calculate and append training and validation accuracies for each class\n",
    "    for i, class_name in enumerate(train_dataset.classes):\n",
    "        class_index = train_dataset.class_to_idx[class_name]        \n",
    "        # Calculate and append training accuracy for the class\n",
    "        train_acc = (class_train_correct[class_index] / class_train_total[class_index]) * 100 if class_train_total[class_index] != 0 else 0\n",
    "        class_metrics[class_name][\"train\"].append(train_acc)\n",
    "        # Calculate and append validation accuracy for the class\n",
    "        val_acc = (class_val_correct[class_index] / class_val_total[class_index]) * 100 if class_val_total[class_index] != 0 else 0\n",
    "        class_metrics[class_name][\"val\"].append(val_acc)\n",
    "\n",
    "        #calculate classwise precision and recall\n",
    "    for i, class_name in enumerate(train_dataset.classes):\n",
    "        class_index = train_dataset.class_to_idx[class_name]\n",
    "        # Calculate precision, recall, and F1 for validation for each class (labels = [class_index] to calculate for each class)\n",
    "        val_precision = precision_score(true_labels_val, predicted_labels_val, labels=[class_index], average=None)\n",
    "        val_recall = recall_score(true_labels_val, predicted_labels_val, labels=[class_index], average=None)\n",
    "        val_f1 = f1_score(true_labels_val, predicted_labels_val, labels=[class_index], average=None)\n",
    "\n",
    "        # Append these metrics to the class_metrics dictionary\n",
    "        class_metrics[class_name][\"precision\"].append(val_precision)\n",
    "        class_metrics[class_name][\"recall\"].append(val_recall)\n",
    "        class_metrics[class_name][\"f1\"].append(val_f1)\n",
    "\n",
    "\n",
    "    # Calculate weighted precision, recall, and F1 for validation for entire validation loop \n",
    "    val_precision = precision_score(true_labels_val, predicted_labels_val, average='weighted')\n",
    "    val_recall = recall_score(true_labels_val, predicted_labels_val, average='weighted')\n",
    "    val_weighted_f1 = f1_score(true_labels_val, predicted_labels_val, average='weighted')\n",
    "    val_macro_f1 = f1_score(true_labels_val, predicted_labels_val, average='macro')\n",
    "\n",
    "    ### Scheduler step\n",
    "    prev_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    if LRScheduler == \"ROP\":\n",
    "        # Get previous learning rate before step\n",
    "        # Update learning rate based on avg F1-score\n",
    "        scheduler.step((val_weighted_f1 + val_macro_f1) / 2)\n",
    "        # Get updated learning rate\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "    else: \n",
    "        scheduler.step()\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Print only if learning rate has changed\n",
    "    if new_lr < prev_lr:\n",
    "        print(f\"\\033[93mLearning Rate Reduced: {prev_lr:.6f} → {new_lr:.6f}\\033[0m\")\n",
    "\n",
    "    #append label values\n",
    "    true_labels_list.extend(true_labels_val)\n",
    "    predicted_labels_list.extend(predicted_labels_val)\n",
    "    \n",
    "    # Store F1 values\n",
    "    macro_f1_scores.append(val_macro_f1)\n",
    "    weighted_f1_scores.append(val_weighted_f1)\n",
    "    epochs_list.append(epoch)    \n",
    "\n",
    "    # End the timer and calculate elapsed time\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f\"Time taken for validation epoch and calculations {epoch}: {epoch_time:.0f} seconds\")\n",
    "    \n",
    "    #Print metrics for individual epochs here:\n",
    "    print(f'Epoch [{epoch}/{num_epochs}]')\n",
    "    \n",
    "    #print(f'Individual epoch metrics per class:')\n",
    "    # Print metrics for each class from class_metrics3 - these should be different each epoch. \n",
    "    for class_name in train_dataset.classes:\n",
    "        TP = sum(class_metrics3[class_name][\"TP\"])\n",
    "        FP = sum(class_metrics3[class_name][\"FP\"])\n",
    "        TN = sum(class_metrics3[class_name][\"TN\"])\n",
    "        FN = sum(class_metrics3[class_name][\"FN\"])\n",
    "    \n",
    "        # Calculate precision, recall, and accuracy for each class\n",
    "        #precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "        #recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "        #accuracy = 100 * (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) != 0 else 0\n",
    "        #print(f'Class: {class_name}, Training Accuracy: {class_metrics[class_name][\"train\"][-1]:.2f}%, Validation Accuracy: {accuracy:.4f}%, '\n",
    "        #      f'Precision: {precision:.4f}, Recall: {recall:.4f}') \n",
    "\n",
    "        # Early stopping and best model tracking\n",
    "    if val_weighted_f1 > best_weighted_f1 and val_macro_f1 > best_macro_f1: # If using \"and\", both must improve!\n",
    "        best_weighted_f1 = val_weighted_f1\n",
    "        best_macro_f1 = val_macro_f1\n",
    "        best_model_wts = model.state_dict()  # Store best weights in memory\n",
    "        epochs_without_improvement = 0  # Reset counter when improvement is found\n",
    "        print(f\"\\033[92mNew best model detected! Weighted/macro F1-score: {best_weighted_f1:.2f}/{best_macro_f1:.2f} at epoch {epoch}\\033[0m\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"\\033[93mNo improvements detected. Weighted/macro F1-score:{val_weighted_f1:.2f}/{val_macro_f1:.2f}\\nEpochs without improvement: {epochs_without_improvement}\\033[0m\")\n",
    "\n",
    "    # Check early stopping condition\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"\\033[91mEarly stopping triggered at epoch {epoch} due to no improvement in {patience} epochs.\\033[0m\")\n",
    "        print(f\"\\033[92mBest model had: Weighted/macro F1-score: {best_weighted_f1:.2f}/{best_macro_f1:.2f} at epoch {epoch}\\033[0m\")\n",
    "        break  # Exit training loop\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116134b",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "save_path = rf'.\\Models\\{num_classes}.pth'\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'training_loss': train_loss,\n",
    "    'validation_loss': validation_loss,\n",
    "    'training_accuracies': train_accuracies,\n",
    "    'validation_accuracies': validation_accuracies,\n",
    "    'true_labels_list': true_labels_list,\n",
    "    'predicted_labels_list': predicted_labels_list,\n",
    "    'class_mapping': train_dataset.class_to_idx,  # Save the class mapping\n",
    "    'num_classes': num_classes,  # Save the number of classes\n",
    "    'normalization': {  # Save normalization values\n",
    "        'mean': calculated_mean,\n",
    "        'std': calculated_std\n",
    "    }\n",
    "}, save_path)\n",
    "\n",
    "print(f\"Model and additional data saved as {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8022fb",
   "metadata": {},
   "source": [
    "# Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint\n",
    "checkpoint = torch.load(save_path, map_location=device)\n",
    "\n",
    "model_class_mapping = {v: k for k, v in checkpoint['class_mapping'].items()}  # Reverse mapping for index-to-class name\n",
    "\n",
    "# Initialize the model and load weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f2e25",
   "metadata": {},
   "source": [
    "# Final Validation and Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track predictions and labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in validation_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Directly use predictions and labels as they are already aligned\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "print(\"Test done.\")\n",
    "\n",
    "# Generate the classification report directly\n",
    "report = classification_report(all_labels, all_preds, target_names=validation_loader.dataset.classes)\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix calculated with % of each class.\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Normalize the confusion matrix to percentages\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Define class names directly from the dataset\n",
    "class_names = validation_loader.dataset.classes  # Assumes the dataset has a 'classes' attribute\n",
    "\n",
    "# Create a heatmap with percentages\n",
    "plt.figure(figsize=(24, 20))\n",
    "sns.heatmap(cm_percentage, annot=True, fmt=\".0f\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix (Percentage)\")\n",
    "\n",
    "# Save the figure to a file\n",
    "#plt.savefig(rf\"C:\\Users\\kriss\\Documents\\HI Jobb\\Confusion matrix\\Run{run_nr}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13e75a",
   "metadata": {},
   "source": [
    "# Plot Precision, Recall, Accuracy, Loss and F1 scores per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of classes\n",
    "classes = train_dataset.classes\n",
    "\n",
    "# Loop through each class and create precision and recall plots\n",
    "for class_name in classes:\n",
    "    # Get precision and recall values for the current class across epochs\n",
    "    precision_values = class_metrics[class_name][\"precision\"]\n",
    "    recall_values = class_metrics[class_name][\"recall\"]\n",
    "    \n",
    "    # Get the actual number of completed epochs for this class\n",
    "    actual_epochs = len(precision_values)\n",
    "    \n",
    "    # Create a new figure for each class\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(f'Precision and Recall for Class: {class_name}')\n",
    "    \n",
    "    # Plot precision\n",
    "    plt.plot(range(1, actual_epochs + 1), precision_values, label='Precision', marker='o')\n",
    "    \n",
    "    # Plot recall\n",
    "    plt.plot(range(1, actual_epochs + 1), recall_values, label='Recall', marker='x')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show the plot for this class\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229cdd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Macro F1\n",
    "plt.plot(epochs_list, macro_f1_scores, label=\"Macro F1\", linestyle=\"-\", marker=\"o\")\n",
    "\n",
    "# Plot Weighted F1\n",
    "plt.plot(epochs_list, weighted_f1_scores, label=\"Weighted F1\", linestyle=\"-\", marker=\"s\")\n",
    "\n",
    "# Formatting\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"Macro & Weighted F1 Score Over Training\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed9673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation losses. Big gap indicates overfitting.\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, actual_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, actual_epochs + 1), validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
